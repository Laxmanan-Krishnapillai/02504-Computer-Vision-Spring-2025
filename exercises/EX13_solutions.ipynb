{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise 13: Structured light\n",
    "\n",
    "Solutions for the week 13 exercises. We follow the lecture terminology on structured light, phase shifting, and stereo triangulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 13.1\n",
    "If the cameras were not calibrated we would first estimate their intrinsic parameters using a planar calibration target.\n",
    "Multiple views of a known pattern, e.g. a checkerboard, allow us to recover the intrinsic camera matrix $K$ and distortion coefficients by minimizing the reprojection error.\n",
    "The relative rotation $R$ and translation $t$ (extrinsics) between the cameras can then be obtained with stereo calibration once the intrinsics are known.\n",
    "This follows the standard pinhole model used throughout the lectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 13.2\n",
    "The images are first undistorted and rectified so that epipolar lines align horizontally.\n",
    "The code below loads the calibration dictionary, prepares rectification maps, and stores the processed frames in two lists `ims0` and `ims1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": 0,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data_dir = Path('exercises/ex13_data')\n",
    "c = np.load(data_dir / 'calib.npy', allow_pickle=True).item()\n",
    "im0 = cv2.imread(str(data_dir / 'sequence/frames0_0.png'))\n",
    "size = (im0.shape[1], im0.shape[0])\n",
    "stereo = cv2.stereoRectify(c['K0'], c['d0'], c['K1'], c['d1'], size, c['R'], c['t'], flags=0)\n",
    "R0, R1, P0, P1 = stereo[:4]\n",
    "maps0 = cv2.initUndistortRectifyMap(c['K0'], c['d0'], R0, P0, size, cv2.CV_32FC2)\n",
    "maps1 = cv2.initUndistortRectifyMap(c['K1'], c['d1'], R1, P1, size, cv2.CV_32FC2)\n",
    "\n",
    "ims0, ims1 = [], []\n",
    "for idx in range(26):\n",
    "    im0 = cv2.imread(str(data_dir / f'sequence/frames0_{idx}.png'), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "    im1 = cv2.imread(str(data_dir / f'sequence/frames1_{idx}.png'), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "    ims0.append(cv2.remap(im0, *maps0, cv2.INTER_LINEAR))\n",
    "    ims1.append(cv2.remap(im1, *maps1, cv2.INTER_LINEAR))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1); plt.imshow(ims0[0], cmap='gray'); plt.title('cam 0')\n",
    "plt.subplot(1,2,2); plt.imshow(ims1[0], cmap='gray'); plt.title('cam 1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 13.3\n",
    "We unwrap the phase for each camera using the heterodyne principle.\n",
    "The function below follows the lecture derivation: Fourier analysis obtains the wrapped primary and secondary phases, the order of the primary phase is found from the phase cue, and the absolute phase is recovered.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": 0,
   "outputs": [],
   "source": [
    "def unwrap(ims, n_primary=16, n_secondary=8):\n",
    "    prim = np.stack(ims[2:2+n_primary], axis=0)\n",
    "    sec = np.stack(ims[18:18+n_secondary], axis=0)\n",
    "    fft_p = np.fft.rfft(prim, axis=0)\n",
    "    fft_s = np.fft.rfft(sec, axis=0)\n",
    "    theta_p = np.angle(fft_p[1])\n",
    "    theta_s = np.angle(fft_s[1])\n",
    "    theta_c = theta_p - theta_s\n",
    "    o_p = np.round((theta_c + np.pi) / (2*np.pi))\n",
    "    theta = theta_p + 2*np.pi*o_p\n",
    "    return theta\n",
    "\n",
    "theta0 = unwrap(ims0)\n",
    "theta1 = unwrap(ims1)\n",
    "plt.imshow(theta0, cmap='hsv'); plt.title('theta0'); plt.colorbar(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 13.4\n",
    "A binary mask discards pixels with insufficient projector illumination.\n",
    "We threshold the difference between the fully-on and fully-off images.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": 0,
   "outputs": [],
   "source": [
    "mask0 = (ims0[0] - ims0[1]) > 15\n",
    "mask1 = (ims1[0] - ims1[1]) > 15\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1); plt.imshow(mask0, cmap='gray'); plt.title('mask0')\n",
    "plt.subplot(1,2,2); plt.imshow(mask1, cmap='gray'); plt.title('mask1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 13.5\n",
    "Rectified images allow correspondence search along rows. For each valid pixel in camera 0 we find the pixel in camera 1 with closest phase and record the disparity.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": 0,
   "outputs": [],
   "source": [
    "h, w = theta0.shape\n",
    "q0s, q1s = [], []\n",
    "disparity = np.zeros_like(theta0)\n",
    "for i in range(h):\n",
    "    for j0 in range(w):\n",
    "        if not mask0[i, j0]:\n",
    "            continue\n",
    "        phases = theta1[i, mask1[i]]\n",
    "        js = np.where(mask1[i])[0]\n",
    "        j1 = js[np.argmin(np.abs(phases - theta0[i, j0]))]\n",
    "        q0s.append([j0, i])\n",
    "        q1s.append([j1, i])\n",
    "        disparity[i, j0] = j0 - j1\n",
    "plt.imshow(disparity, cmap='inferno'); plt.title('disparity'); plt.colorbar(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 13.6\n",
    "Using the projection matrices of the rectified stereo pair we triangulate the matched pixels to obtain a 3D point cloud in the camera 0 coordinate frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": 0,
   "outputs": [],
   "source": [
    "q0 = np.array(q0s, dtype=np.float32).T\n",
    "q1 = np.array(q1s, dtype=np.float32).T\n",
    "Q = cv2.triangulatePoints(P0, P1, q0, q1)\n",
    "Q = cv2.convertPointsFromHomogeneous(Q.T)[:,0]\n",
    "Q = Q[Q[:,2] > 0]  # keep points in front of cameras\n",
    "# Visualization (requires Open3D)\n",
    "# import open3d as o3d\n",
    "# pcd = o3d.geometry.PointCloud()\n",
    "# pcd.points = o3d.utility.Vector3dVector(Q)\n",
    "# o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 13.7 (optional)\n",
    "Color information can be added by sampling the rectified color images at the matched pixel locations and assigning these colors to the 3D points before visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 13.8 (optional)\n",
    "Sub-pixel matching refines the disparity by linearly interpolating the phase responses along the epipolar line to locate the phase agreement with fractional pixel precision.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}