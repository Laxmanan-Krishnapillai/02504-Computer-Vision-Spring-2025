Speaker 1: Hello everybody, so now it's one o'clock Friday afternoon. Very nice to see so many of you here for the first lecture in Computer vision. So my name is Anna Stael and I will be giving the first lecture and then and then Theodore who's sitting here. She'll be giving the the second lecture and then we'll need to figure out what have I'll come back then and then We'll figure out but actually we are here because we are we are We are running are we starting up the course for Morton who who's usually the the the one giving the the lectures in the computer vision course So but we'll do fine. 

It'll be fun and and we will I think follow along and and and and also be part of preparing your exam and so on so Good so I am right now recording the the lecture So just to know that that when you ask questions during the lecture and so on it'll be on the recording I hope it's it's fine with everybody Because I also hope that you will you will ask questions whenever you get some questions and interrupt and Correct me if when I do something wrong So that we we learn along the way the best thing is to to interact for you to learn and that's also completely fine to interact during the lectures So the the plan is that we will have Lectures first and then following by by having some exercises and there you would Definitely get to interact because that's you who I will be doing the exercises So the normal teacher he is here. That's that's Morton and you will recognize him when he comes but I just Put in a little bit about me. So I am a Professor from the view compute where I'm working with computer vision and image analysis and So I did my my pst in computer vision back in I finished in 2009 So I work with also various applications in Computer vision and especially 3d image analysis. I'm doing a lot of research in in Volumetric data so micro CT and similar and to door here You can introduce you'll be introducing yourself more next time But you have a also a background in computer vision has just started with us here first of January and and it's an expert in especially in 3d point clouds and segmentation but also knows a lot about computer vision so So that's you you're in safe hands Both with me and and to do until Morton is back and then when he will he will have to catch up on anything we've If he disagrees he should just be here. 

So that's good. So computer vision is about that you Yeah, so the topic I guess you you all had your motivation for for signing up for this course And it's it's I think it's a very very good idea that you did sign up for it because it's it's great fun the the purpose of doing computer vision is that you have a Camera and then it can record some images and then it's it's the process of getting information from these images to have a system that makes some kind of decision and therefore the vision part is of course the visual input to make decisions and So so popular saying you could say that it's it's making machines see and perceive But it is it is typically something you use when you say that okay. We need to Do something downstream with this data, but it's also all the image processing part. So it's Computer vision is a very very broad term That that also covers that you get an image in and then you do something you get a segmentation out Or you get a point set in and then you do something and then but it's it's typically from it or it is from visual data And in this course we will in particular be focused on Using the camera as an instrument for measuring the world around us. So especially due geometric parts of computer vision So You need More the way that that that our brain This is this is gonna give me troubles But hopefully if it sounds weird then just say stop speaking and then we'll try to correct it and so We all know we can take a photo when I started in vision It was We had digital cameras that but the phone cameras were really poor at that point, but it has improved a lot so everybody is is walking around with with a Quite good camera in their pocket and and taking images at that time some of the standard algorithms or I think they are they are termed filters in in the in the A mobile phone camera lingo was something that was that was very impressive and very cool But but it's more difficult to impress you with doing image stitching and and alignment and so on Now because it is more or less standard in a lot of software so We will However be working with the underlying mathematics and underlying Algorithms to ensure that that that these Systems work because there's a lot of of Important applications that are based on on on the models from computer vision so it's about recognizing features in images and measuring Links and sizes and so on by using perspective cameras either one or several cameras So the core elements We will work with 3d and in this Here it's modeling typically from from point observations modeling the world and where Where things are in the 3d world so we will work with the camera model Multi-view geometry so several cameras We will work with 3d reconstruction or you will work with 3d reconstruction and then and all of this a very important machinery behind this is to identify Uniquely localizable points in images So finding feature points and being able to match these feature points and from that Derived the geometry today where we will be working with homogeneous coordinates in the camera model We we are not so concerned with where does these points come from that'll come later on and then You will be able when you're done with this course you'll be able to take images make vision setups and start Building your own systems to record geometry from cameras and that's that's pretty cool. So Hopefully it will excite you as much as it has excited me Working with this area Just to to let you know this is not the only course that that that touches this but there are several others So so how how many of you have had the Either the introductory course 2502 in image analysis or a similar course in introductory image analysis So that's I would guess about half of you good So you know something about working with images at least some of you How many have had an introductory machine learning course? Oh, that's a lot so a lot of Vision and and a lot of these applications are also very much based on on like fundamental machine learning or also very advanced machine learning so Especially the area of deep learning has become Tool or tools from deep learning has become Playing a larger and larger role for for computer vision and we are also teaching a course in that you'll not meet it here but but When you want to apply some of the techniques that we are learning here in the real world for for on on images It can be very convenient to do some of the processing using deep learning techniques and therefore It's it's good to know that's also out there and so of other Courses in in vision and image analysis we have two courses in deep learning for computer vision We have this introductory course in the fall deep learning in computer vision and then we have advanced deep learning computer vision that runs in the spring and then Parallel to this course on Wednesdays. I'm also teaching advanced image analysis where we where we are looking at Techniques for for image segmentation and also image geometry and we touch a little bit on Deep learning in that course as well. So there are other options and I don't know perhaps some of you already had some of these courses This course is of course 13 weeks because it's a spring course and we will do it with the 12 weeks of Topics in computer vision everything is gonna cover which computer vision But but where you will be preparing for the exam and then there's one week with a guest guest lecture and that's I guess will be flag Tugson who is Director of The company called track man where they do they do golf Tracking using a radar system, but they have also Implemented a lot of computer vision algorithms in in there in their work So so they have a radar they use when they do When you play golf that can Monitor how you are performing on and then they also have a system to for example overlay the golf ball on a on a on a camera That is that is real time recording what's going on then you get these tracks I don't know if you've ever seen what's golf, but there comes these tracks on the screen and they they are building the system for Displaying these tracks so that that that's a practical application of computer vision and and Spot on for the things you learn in this course So We will Have lectures normally by modern but now to do and I I have these These slides from on and perhaps I didn't correct everything because it should have said that that modern and others will will Do this and so for the exam there'll be a The grade will be based on the written exam, which is a four hours multiple choice exam we Were discussing if it should be an oral exam, but now I made the decision No, we you're too many to do an oral exam and it's much more fair to judge you on a written exam So so let's stick to that so it'll be a written exam four hours multiple choice where you will be doing Tasks that are very similar to what you meet in the exercises But it's of course adjusted to the time you have at the written exam Then we will also have some weekly quizzes and that is That's something I just need to check up on afterwards Exactly how how you you hand in there? 

It does not affect the grade at all the purpose with the weekly quizzes is just to give you and a chance of Trying out something that that resembles the questions you'll get at the exam So it's you know when when you do course evaluation you have the question saying did the teacher give you individual feedback on where you stand and And this is one way of one part of this is this weekly quizzes So so it's we give you that by you doing it yourself So you try solving the weekly quiz and then you get the feedback if you did it correct or not but there's also the exercises where We will be here. There will be TAs coming as well and They will come at three o'clock and and they can also give you some some some feedback And the reading material we have a Book so so every week I'll go to learn just in a second to show you where it is But there's a book by Richard Sileski on Computer visions algorithms and applications where there's some something to read. There's lecture notes by Henrik Wohnes Where there's also something for you to read then there are two papers That you should read for the I think these papers are concerned with camera calibration And then if you would like some additional material, there's this Fantastic book by Hartley and Sisseman on multiple view geometry in computer vision And I think you can even get it get it online And that is that's a really good book, but it gives also a lot of detail so so the the lecture note by Henrik is It has a few mistakes and so on but it has like cut away all of the all of the Details and and gets to the point of what is important. So so that's a very good place to start So so it's like an easy way in and I also encourage you to read it's it's it can be very rewarding We've been discussing will students at all read and perhaps I will Should we do something where we ask them questions about the reading material every time so we So make sure they read And I will not but of course it's a it that is where the information is So if there's anything in the exercises that you're in doubt about It can be a good idea to go to the source and and that is easier to find if you already read it once so so Familiarize you with the reading material. That's a very good idea Exercises they are available on this you learn there's no Hands in And then it says some solutions. So I guess that's that's more than that that gives you the the solutions along the way I'll make sure that that for these first weeks that it's uploaded and made made available for you But it's a very good idea to do the exercise in groups So not sit necessarily alone with everything but have someone to discuss it with while you're here And then you can finish them when you when you are done with the with the exercise there will be two TAs coming and and I'll introduce them. They are here at three o'clock and they will be Here to help you and I have instructed them To help you to help yourself So don't get Annoyed with them if they instead of giving you the answer to the question that you have if they ask you Some questions about where you where did you look and how how can you find your the answer yourself and so on? That's because I told them to so so so then yeah If you really insist they will probably give you the answers so that that should be fine and So it also what says here learn how to debug from them. So so use them to To see that if you think about it in the exam situation or in that's not so interesting The most interesting thing is that when you're going to use it afterwards So when you're going to make a project on computer vision, which Hopefully many of you will be working with because it is Very much fun to work with Then you don't have anyone that can come and give you the answer and therefore it's a really good skill To have learned where can I find the source to get the answers to these questions that I have and A lot of things are written down. 

So so that's also why it's a good idea to read about it. Um, Yeah expectations That is this is this is Mortens expectation. So so he expects you to complete all the exercises before the final exam That is a very good idea because it is by doing the exercises that you learn the content that you will be questioned about at the exam if you skip some things you might be lucky that we don't ask questions in that but don't count on We'll probably try to we will try to cover the the pencil much good as possible But if you have done the exercise and you've done it yourself so so that You have been the ones coding it You'll all to be well very well prepared for the exam So therefore it's a good idea to do the exercises And then it there's a little bit of of of A Dependence is between exercises and so on and therefore it's a good idea also to keep up with the exercises per week I Think that it should be doable remember that that a five is just course equivalent or is equivalent to spending nine hours per week on that course So so you spend four hours if you're here for the lecture and stay for the exercise And then you should spend five hours beyond that so it's actually quite a lot of time that you you have for the course And and that's what we've tried to adjust the content to Then it's a good idea that you engage discuss with each other and so on during the during the course and during especially the the exercises and then talk to t.a. And A Week after the exercise you get a get a PDF of the results Apparently not exactly the solution There's a few details here that that i'm gonna follow up on just to make sure that that i'm doing it in the the way that modern intended Yeah, so feedback is welcome throughout the course I think modern has a system where he asks two people to give feedback every week, but i'm If you want to give me feedback you're welcome But otherwise let's just discuss Through the course and i'll go around and ask you at the exercises Good I think this was this was the the the the intro slides So let me hear Uh, do you have some questions or what questions do you have for the for the practical things in the course? Doesn't it's very quiet so so any any thoughts about what you expect from from taking this course. What are you going to Use it for so how yeah 

Speaker 2: Yes Or are we gonna be given a specific Scripts that we can modify to get what we want 

Speaker 1: you'll primarily be Using some python libraries Are all writing in python. Is there anyone that wants to do it in mad lab or c or julia or something? How many will be working will not be working in python Does oh that was That was good. No, no you'll be Most of it will will be things that you just code up From from scratch. 

There are a few things as you see in the first exercise. There's a there's a small Function that that's written in the pdf that you can copy over And and use but otherwise it's it's it's not huge frameworks that There are some huge framework behind but that's python packages that we just import and and use Yes So so it it is Practical in the sense that we expect you to learn To be able to to to read The mathematical notation Implemented in a python program and make it work. And that's what you will be demonstrating at the exam That is this ability to implement and get the right numbers. So so you get a For example an image and some a task to do and then you we expect you are able to run it in a way such that you get the right Computation out of it and this way it's practical, but it requires of course a theoretical understanding of what What is behind the algorithm? What what is it you are actually solving? 

Other questions Comments So What could I come up with asking you anyone any thoughts on on why you've chosen this? Yes Ah, that's good. It is cool. It is very cool, but I can I can easily say that but you'll experience it when you when you start working and Yeah, I can also only encourage you to as we get into the course to play around If take some photos yourself and and try out some of the algorithms, it's it's great fun so so and Yeah Measuring the size of things by measuring its size in the image. 

That's cool that you can do it. So good But I will now I'll spend I don't know The next 20 minutes or something starting up with the lecture Then we'll take a short break and then I'll finish and then you'll go to the exercises but Perhaps I should for the practical stuff just go to Learn now I'm going to view it as student and So this is um How computer vision looks from the from the learn side and as The important thing is here that we have the content and here you can see the overview of the course and then there's for each week a Some lectures I didn't update with these slides. I think I did only slide modifications, but I'll just update the slides So there here Uh, and there's a reading material. So that was what I talked about. So this is the lecture note So this is this can I go on this lecture note one one to one for one and there's celeski That's the the book from Richard celeski on computer vision and the chapters there you should read Uh, and then there's an exercise and that is just a pdf explaining What you should do and you can see this is this is uh modern who has compiled this I didn't make any changes and that is on today's topic on homogeneous coordinates and And camera model and there you can see there's a small Function here to produce some points that's going to be used in the exercise. So that is that's all What we that's a that's even answers to the to the exercise here at the bottom But try to do them instead of instead of jumping right into the answers I'm actually in doubt if I should have removed these answers I should probably have and just giving them to you next year now you have them so but but try to solve the exercise without Looking too much at the answers to begin with because then you learn more, but I think these first exercises are relatively doable so But let's see that of course depends on a lot of things so I will now Go to the other slides that I have on the This camera model and homogeneous coordinates So what does it say? We say yes, it's okay. 

And then we do like this Let's see This should be fine No, well, why did it? Let me just I Just didn't have patience enough good So we're going to talk about Pinhole camera and homogeneous coordinates So I'm going to both use the board and and the slides So you should Learn something about homogeneous coordinates and How you convert to and from homogeneous coordinates and then Perform relevant coordinate transformation. This means rotations and translations And and also understand why this is this is a need to do using homogeneous coordinates Compared to just being in the the in homogeneous coordinate system And then also be able to explain I would also say you should also be able to implement and project data from the pinhole camera model So you can take some points project them to an image plane Given the camera geometry and understand all the parameters that that goes in That should be What we will expect from you when you you get an assignment later so This is today's topics And here's uh, yeah all the things will go through and I'll Get to it as as we go along. So so we start with the pinhole camera So you should The pinhole camera is a model of a camera But it's Um It is of course not the way that a camera functions Because the camera has optics and and and a lot of things But yet it is a model that is is uh sufficiently good that we can easily use it for computer vision So so despite that a light is doing Other things than than what we model in the pinhole camera model. 

It is still The basis of a lot of the computer vision we do So don't be mistaken that that that we are not using a pinhole camera But the model anyway Is is sufficiently good to be used for computing the geometry that that we want to so the let me just Give you some some Basic explanation about the the pinhole camera model. So so so if you think of it we we have If we have uh some I'd say we have a light source. We have the sun out here And then we have some some objects. 

So we have a tree In the real world, right? So the launch the the light from the sun spreads And and and hits the surface of the tree and then we observe it with a camera And then we you you should imagine that that we are looking Uh, we we have some some kind of of screen where there's a little tiny hole So a box like this with a little tiny hole And uh on the back side of this box we we can record an image And then if the We know that that light that that hits the surface of the tree here will be uh be Reflected off the surface of the tree and spread again out in the world. So it's it's quite Wild to think about that the light here is like hitting the surfaces everywhere and and spreading everywhere and so on But if we just look through something that that has a very very tiny hole So so uh infinitely small. So just one photon at a time can go through Then and and we assume that light is traveling Along straight lines and we can assume that quite safely for everything that's uh in the That that that we're looking at with the camera here. So so Because of heat and because of long distances and so on you will sometimes see that that that light is actually not Moving completely straight. You can see this if on a hot day You would see that that it it that there are some shadows or some some flickering of light because something happens But we ignore that we just and and and that's safe to ignore for for all the practical purposes so The light that hits here will then go in a straight line and now i'm i'm gonna try to do this As good as possible. So imagine that this line is straight. That's where the light From this point then ends on the camera And then if we we we we take another point in the in the image here It'll come from here and so on and this way We will through this small point in our camera Produce an image on the back side of the camera. 

So now i'm gonna Write it up in a in a different way. So if we Imagine that this Is a point that all the light is going through Then we would have the our tree here Something like this and then we have a point Through which the all the light from the tree goes through and then we have a an image plane Some place behind this Behind this point and then all the then you can imagine that that that we get All the information here and you'd get an image of the tree So if we take this and put it out we will get the mirrored version of this So we will get something that has a tree on the image So we'll get an image that that that kind of turns this thing upside down So that's the that's the basic of the key. That's the basic principle behind the pinhole camera model So you can see it here We have light Travels in straight lines We can accept that and then the projected image appears upside down That's not a problem With modern cameras that on that that's recorded on a on a digital sensor. It's just a matter of how we read out the pixels And then what is physically going on is that the Photon spread from here is distributed into the Into the world and then only the rays that comes from this point will end up here But what we in practice do with a real camera is that we have a lens system And I can I'll draw that by the end of the lecture But but the lens makes sure that it's just not photons that goes in that exact line, but actually cone of light That comes from here that then hits a lens and that lens can then collect the light going again through a point the so-called principle point and that point is then ensuring that that only Only the light that comes from a certain position on the object that we are observing Will hit the camera if if if not We'll see it blurring and that's what you Typically see as as the depth of field that that you can only see a certain part of the image But we're not gonna we're not gonna go into details about this now But but in principle it is this pinhole camera model And and and then we use lenses to to collect more light and then actually enable us to see just like our eyes is doing So each point In an image also corresponds to a direction. So when we have this Pinhole camera model, we will Have the principle point which is here And then if you pick a pixel on this It it goes always through this point So this means that Any point that goes or any any pixel on this if you know the Placement of the camera. So we have a coordinate system of the camera and we have a coordinate system of the world We will be able to tell Where in the world that does this? 

a pixel correspond to but not not exactly the the the the 3d coordinate But we will know that it's the this pixel is restricted all the the the the light that comes to this pixel Is restricted to come from somewhere Along this line We just don't know exactly how far out it is But if we have a point in the 3d world We will know how it'll pretty and we know the geometry and so on that's what we'll get to with the camera model Then we know what it projects to in the image and that's the important point good And now I will skip this. I don't know exactly the two volunteers. I forgot to To to look through what what should be done with the volunteers. It would probably be a fun thing So so modern is is is really a funny guy. So he probably had some some Sketchy thing he would do with you now, but I'll skip that. 

Sorry about that. Um, so Yeah, so this is this is just to I think this is just to make the point that if you have two cameras Looking so now I had the straight line here and then you have a Another camera here with with with another principle point and then knowing that that if you have a Some point On the camera here that sees the same thing. So so so if we observe the same Point here on the camera, we will know that and and we know the Relative geometry of these two cameras We will know that that since they the point should be on both lines We will also be able to estimate where in 3d did this point come from and that's that's the principle behind a multiple view geometry Not start there, but that's what we will be building up to Good so, um perspective transformations This was the Less advanced Sketch that I did that I made out there, but now there's something more introduced here. We have an f So, um You can either model it model the the pinhole camera this way with the with the image upside down But we can also make a model where we say That we have the camera here. So this is this is the the the detector We have a a a principle point and then then everything is is is behind and and you see this this part of the world But we could also place this camera on the other side such that any point coming from Now it's a person standing here Right any point from this person We we know that it it should go through this, but if we then model it as As as an image plane here We will have the the like not the mirrored version, but just the the the The projected version of of the the object that we are we are observing and that's what's illustrated here So so you can see these two balls on top of each other then projected to the image here And and but but it's it's just an easier way of of illustrating it So just think of it as an image plane that lies in front of the principle point and then there's this f Which is a the distance from the principle point To the image plane So this distance is f And that's of course the same here. 

So so this is just mirrored. So this is just f And this focal length is important for the for when we get to to modeling the camera geometry So we have yeah the principle point and the focal length And then we have the image plane and now here here drawn drawn in a in a 2d version But but think of it. It is a 3d thing going on Good so now we come to perspective projections. I think that's that's where it starts getting Really exciting So Let's say we start in 2d again and then we have a vector. So let's see say we call it v So we have a vector v which has the v x component. So we just write it like this v x and v y Like this good Then we can So I just want to write that V is in two dimensions Good. So this is this is our 2d vector Then we for for A Transforming this point. 

What can we do to it? um, so this is You know, this is let's just write a coordinate system. So So we have here x and we have y and we have the point v And then we can choose to do something to this v we can take the v and we can we can rotate it meaning that we we if we just Apply a rotation to this it'll be rotating around the origo of the coordinate system So we can choose to let's say we rotated along an angle of of That we call theta and then we get to a point here. So this is it should be at the same distance So this would be the rotation with the rotation matrix r And then we could also choose to translate it. So with a vector t So that would be an an operation we can do to v So so the way we would do this with Matrix vector notation is that that we can take The V so we get a new point v mark, which is the transformed point And then we can do just a matrix r V matrix vector multiplication plus t right so What is the in 2d the dimensionality of a rotation matrix? 

How big is that? Anyone So This is a 2 by 1 vector, right? Yes It's 2 by 2. Yes, exactly and Let me see. 

I cannot push it up anymore. I'll just write it here So it's a 2 by 2 and and in in 2d. So if we rotate with the the the angle theta It's just the cosine of theta minus sign Of theta A panel this minus is a little bit depending on the convention. It might also be down here and then the sign of theta and then the cosine of theta and there's a an equivalent a simple Expression for in 3d where it's products of angles, but in 3d you'll have More angles that you you rotate around so it becomes a little bit more more complicated But this is this is the rotation and then the translation. That's just a vector. 

So so So let's just write it like this that t equals this vector t x and t y right Good everything is fine. We can do this and and and this is just this is just a transformation but uh Yeah, so I just actually wrote let's try to implement this. Let's yeah, let why not we can try to implement it Let's see I have visual studio code somewhere and So you can see it now Should be big enough. Perhaps it's even more than big enough I'll remove this make a new file save it and then So just I'm just going to to write a little bit of code in in python such that This is what you'll be doing in a in a in a few minutes Of half an hour something So I I like to use these coding blocks in in visual studio code because it it allows me to Run just parts of the code and and and makes things simple And we can just clear it here and I need uh numpy And I need matplotlib. Yes, and it knows and then it even knows I want This widget and I have the packages that I that I need And then yeah, so so we have a point v and then uh It it I did it yesterday. 

So you know it it already remembers what I'm gonna write. So that that's quite nice um That's good. That's co-pilot. That's helping me here. So that's uh Without that I would be completely lost um So so now this was not what I want. I'll I'll do this just in a in a second So so instead I just want to plot the the the Let's just say And then like this this should be fine, right? So so now it it it it plots a nice point here And I'm just gonna steal a little bit of the plotting here because I I'll set the the limits Like this and also the s actually I'm gonna copy This over, you know, it's like tv kitchen. I prepared something from home uh, and then So now it I can I can display it I just wanted to set the limits to something that I can that I can show and and and you can like get a Sense of where the coordinate system is Actually, I could change this to zero, right? 

So this is just a a point at at 3.2. So so nothing Nothing fancy about that. We can also Choose uh to Draw the the the the vector going from zero to this this point So, uh, I'm gonna do like this and you see now it just draws a and a nice line like this Then we can take this point and and let's try to then apply a translation and rotation So let's say that the translation is an array that should be Fine. 

Let's let's choose something that's a little bit more. So we'll make it negative on one side and then We make the the angle 30 degrees. Oh, no, not not not tata, you know, I'm gonna write angle because And and then I'm gonna say that The tata is I mean, I'm just gonna translate it into radians So that's The angle divided and it already knows that it should divide by 180 and then multiply by pi Then I get it in radians and then I can make the and then, you know It already knew what I was going to write here And now we can try to make the the the rotated version of the of the of the vector. Um, so we could also So so this is the rotated and then we afterwards will will apply the translation. So It's just adding the the translation vector and now we can plot the things So so I'm just gonna go go back here steal this plotting from up here and then I have this first thing which is the the first vector And then I'm going from that point here to the to to adding I'm gonna just show the rotation here. So you can see now I have this rotated part and we can also then add the the You can see now it's just this is now the new vector that rotated And then I want to plot from the rotated to the translated And this is just then the three operations together and we end up in this point So this is the this is just and and and you could say you can say that I could choose to I could choose other I'm not going to overdo it because I can choose other parameters here and then then it'll just nicely add to it But but this is the way that you would do these transformation operations simply in 2d doing normal Linear algebra. It's there's nothing not not much to it But but this is just to confirm this works and this is the way it works. So very nice Then we have this this the topic that I'm gonna go into is But couldn't we do this in in a way where we yeah, we have a question Yeah, so so that's what I'm gonna gonna get to that we we're gonna this is this is the first part of deriving The the the the camera model so the pinhole camera model and that's where we're gonna end we're gonna end with one model Where you have a Point in 3d That ends up on the image plane Done in an elegant way where you just multiply the point in 3d space In homogeneous coordinates and that's the point I'm gonna get to now with a matrix and you end up with a with a Point in 2d on the image plane And that's the cool thing that that it's just a a vector matrix multiplication Education you end up with a point that projects to the image plane But but but these values has a relation to the camera geometry and that's what I'm gonna get back to So now we are gonna just cover the the the homogeneous coordinates because the next question is can we do these transformations? In a way where we just do a Vector matrix multiplication. So not having this A thing of adding any suggestions. 

How could we do this? No one wants to tell me did you read about it from home? This is yes Yes, so we add a scaling factor and that's where we are going to use homogeneous coordinates. So the idea is if we take our vector v from over here and then Say that we express it this way that we have The now we're just saying in 2d. So we say Vx V y and then add something and that could be the scaling factor But but we also add that here. So there's a s times vx s times v y and then we have a third coordinate. So we We change it from a 2d to a 3d And the cool thing about doing this is that having this formula We can now do this rotation and translation in one go And oh because this last part down here Is just and when you do when you when you multiply Vectors and multiply vectors and matrices It's it's it's element wise multiplication and then summing up or adding And that's what what we're going to use. So instead of calling it s the we can also choose s just to be one So so that's a choice s equals one and we get the the this one then then We becomes Vx Vy and then one And if we then construct If we want to do this calculation here In homogeneous coordinates, perhaps I should make a special notation. Perhaps I should make it I'll make two lines here to make the special notation for homogeneous coordinates So you don't confuse it from this v over here and then Uh, we can simply just make a construction of the the the rotation and translation Into one Into one matrix and then We we say that and then let's just call this for the transformed Vector We simply just put in the rotation and The the translation And we don't even need these actually because this is just uh What did I call it? 

I called it like this. So now I'm changing notation along the way because this is not necessary Uh, and then we multiply by this guy. So this V double mark and now this is a two by two so And this is two by one right and this is also a two by one And so so Together this matrix becomes what it becomes Three by one because this is just concatenated So this is uh, three by one Multiplied by something this is this is wrong. 

This was three by one. Sorry This is of course this one up here and now if you think about it, we have Uh, this one so, uh V mark Equals and if we write in the numbers, we have the cosine of theta. We have minus sine of theta And then we have the tx And then we have sine of theta We have the cosine of theta And we have ty Right, and then we have the the vector Vx Vy One And when you multiply it out you simply just get a um This Sine of oh no that's wrong. It's cosine of theta of course Multiplied by vx Minus sine of theta multiplied by vy Plus And then you have sine of theta, vx minus cosine of theta, vy plus ty. So now you see the brilliance of going to homogeneous coordinates. And it's this simple trick, just allows us to write up this expression as a matrix vector multiplication. 

And that's the whole point. It's just allowing us to add a thing just using the linear algebra. So it's quite simple. And you'll be writing it up in the exercise, but I think that I already did this in my own demo from home. So this was the matrix multiplication, and then I did the same thing here somewhere. I appended the things. So this is the matrix I call k, it's the rotation and translation. So perhaps I should run everything here so that you see. 

So now I have the k appends the rotation matrix and the translation matrix, where I have, I just do this trick of this is represented in numpy as a 1D array, because it's just a vector, but to get it to a numpy 2D array, even though it's just a 2 by 1 vector, I add this colon dot none, which makes it 2D. And then I also, I don't know actually why I appended this. It shouldn't be necessary. This is just, this is not important. 

Because this, this, this works out fine. So this what I called hn here is just the transformed vector. And now I can, I can also plot it. So this is just showing the same thing as before, perhaps in a little different order. But just to say that the important thing is going on here, that I just take the rotation, the translation, append them together to make this, let's see, this k here, which is just this 2 by 3 matrix. 

And then having the point h in homogeneous coordinates 3, 2, 1, and 1 is the homogeneous part, I can then multiply the two together. Everything is fine. And we're just happy. And that's the, that was the whole point of the homogeneous coordinates. So let's see. So the next thing coming here is the projection from 3D to 2D. 

So let's see. Now I spend an hour. I think it's about time we take a break in this light. It says break in a, in a few slides, but I think we should just stop here. And then I'll, I'll continue in 10 minutes. 

So 10 minutes past two, we will, we will, we'll continue. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Okay, we'll start again. Good. 

We'll start now. So I can see from now I just went a little bit ahead in the slides and I can see that I'm perhaps mixing a little bit up in the order. So some of it we can skip faster over because I already went through it. 

But here's a slide on perspective projection. So that was the thing we talked about here before in the motivation. That we have the point somewhere in... Now I'm just going to... I'm getting a little bit stuck in this. 

Sorry. So we have a point somewhere in real space and we project it through the principle point and we end up somewhere in the image plane. And that is what's illustrated here that you have point P in 3D world. Then it goes through some principle point here and that's now behind the image plane because we have this. We've drawn it using this one, this part over here. 

Oh, sorry. And then this means that from somewhere along this line, so this point, it'll project onto the point here. And you can see that it's important that this focal length here, so the distance from the principle point to the image plane, matters for where on this plane that the point ends up. So when we have a point and now capital P is for point in 3D, we have Px, Py and Pz. And then we want to find the point in 2D and that then becomes this smaller P. I think it's difficult to understand. 

Now I'm just going to make this with two lines so you can see the difference. It's going to be scaled by the distance to the point, so the set distance from the principle point to the point in the real world, the relation between the focal length and this distance is going to be the scaling factor of the x and y coordinates. Now you only see the height here. So it's the focal length divided by this, oh, not r, but Pz, multiplied by Px and Py. So this is the 2D projected point. 

And you'll easily realize this, so we have the principle point, we have the camera plane, we have a line going into the real world, which is now orthogonal to the image plane. And then we have a point, this point P out here, right? And then it goes from here and then I need to hit P, almost hit it. And this point P has a coordinate, so we call this the depth as set and we can here, along this line here, we can call this just x. So the distance here, we call it, that's the Px coordinate, and this distance from here out here, that's what we call Pz, right? And what we can see is that we have two triangles now and we have f here, which is this distance, right? And we have a smaller triangle here, which has the same shape, so this is just the scaled version of the same triangle. And the relation between these is just the relation between f and Pz. So we will know that the height where this 3D coordinate of x projects to in the image is just scaled by f divided by Pz. 

And that's what this just explains. So this is the basis of projective geometry. We are projecting into the image plane by scaling with the coordinate from the 3D world to the distance, so the distance we go out, we call set. 

And so we take the distance from the principal point to the image plane and divide by, and that's the focal length, and divide by the distance to the real world and then multiply the x and y with that. Cool? So that's what you need to know. So Py is just, I'm just writing it here in 2D, but think of it as a 3D point. 

So if you had, I can add that. So let's say we also have the third dimension y here, and then this point would perhaps not necessarily lie exactly in this plane, but be somewhere behind here. So let's just say the point is out here somewhere, but when you then look at it from 2D, it looks like it'll just, the 2D projection of this point will just be here. So this will be the x, and in the depth will then be the y. So it's simply because it is in the 3D world. And that's why we have the y element here. So it's easier to write up the equation than actually making a drawing of it. 

Yeah? This will give the x and y for the bit of the point. So we have the px and py, and that is the image we have here. So it's somewhere in the image. Let's just say that it's a point here in the image. 

That is the px, py point. So if we have the image, we can say that now it's a question of the convention that we want to have. But typically the convention in an image will be that we have the rows as the first coordinate and the columns as the second coordinate, and this means in this that x will be down here. So x will be the coordinate here. So this will be px, and y will be out here. 

So this will be the py. And that's because we think of the image when we represent it in the computer as a 2D array, where the first coordinate is the column, either the row, and the second coordinate is the column. So that's also what you often see. That's r, c, but sometimes you're also plotting things, and then it'll swap it around such that it's the normal coordinate system. We will have x here and y up here, and then there's this conversion of coordinates. So that's also something you'll see in matplotlib when you plot. That if you do the plot, it'll swap the coordinates and also where they come from compared to the image coordinates. 

But this is just to say where from a point in 3D, and you have a camera, where will it land on the camera detector or in the image plane. Good. Then there's quite a lot on rigid transformations here. So this was the talk about homogeneous coordinates now in 3D with a rotation and translation. And that's all very fine. 

And this is an example from real world. If you have a robot arm, you talk about how many degrees of freedom, so where can it turn around and so on. And you'll get a resulting orientation of the gripping point out here through some rotations and translations. And that you can write up this way as a series of rotations and translations. You can write it up using a normal linear algebra like this. And the cool thing is that you can also do it with homogeneous coordinates and we'll get to that now, because I just went through it. So this will be relatively fast and then we can get to the camera model. Because here we have a 3D point, then we add the scaling as I talked about. 

Very good. And we can set the S equal to 1. So in homogeneous coordinates, you can see that this scaling can be chosen freely. 

So you can have a 2 instead of a 1, but then you'll also scale the rest of the numbers. So these two points are the same points in homogeneous coordinates. And then this rotation and translation can be written this way. And then we just utilize the homogeneous coordinates the way that I showed you. 

And then we end up with a system like this. And I left out this bottom part because it was just easier to make it simpler. But typically you'll keep it because then you know after some computation you get your final homogeneous coordinate. And you don't need to be concerned that something happened to this scaling factor because you kept it. And then you can always divide through the coordinate with this to ensure that you are in real coordinates. The first three elements are in real coordinates. And this is then how it looks. 

And what you end up with is that you can do these computations efficiently by a series of matrix multiplications and then multiplying by the vector in the end. And you are done very fast. Good. And then you can go back by dividing through by S. And then we have the break and then we skip the break because we already had it. And then we will continue. And now we get back to where we want to go with this projective transformations. So we are in 3D. 

And as you can guess, this projective geometry can also be written using the homogeneous coordinates. So there's this small detail. I don't think I'm going to spend too much time on this. You will be playing around with it. 

You can test it out yourself to check that it actually works. But the thing is that if you have a line, an equation for a line is you probably are all familiar with y equals A x plus B. We can shuffle a little bit around and then say, but this is equivalent to having the equation that says x plus B y plus C. Now it's of course different B and A than from the equation before. Equal 0. 

That's the same. You can reorder this and get back to the same equation. This means that if we have the x and y, so the point as a homogeneous coordinate, we can do the line equation by saying that we have, let me write it here, that we have a line L multiplied by, so L multiplied by a point P. Now I'm just going to check where we have the transpose. 

I think the transpose is on the line. We imagine the line being a 1 by 3 vector. Because then this will be for the line, we will have A, B and C. So that's the parameters of the line, multiplied by the x, y, right? And this will give this equation and then you set it equal to 0. And all the points x and y that fulfills this will be on the line. 

Very nice. And then the equation for the distance to line point, that's something you're going to use later and that's why this is here. Because the distance, let me write it correctly, is just a point A x plus B y plus C divided by the length of the first two parameters, so A squared plus B squared. So this is the sine distance from a point to a line. 

Good. So any point in 2D space will find the projected distance. This means the distance to the nearest point on the line through this equation. So that means the orthogonal line going to the, from the point then the line that goes orthogonal to this point. 

So this is very nice. And then you can see that the distance can be written as with this equation here, from a point which is not on the line now, but just any point. You can just normalize by this. So if you have 1 divided by the square root of A squared plus B squared, multiplied by L transpose P, right? This will give the distance. So this is just a way of expressing the distance, the projected distance from a point to a line. 

And that can be used if you want to check, if you have some points and you want to check, is this point on the line or at least close to, you can set a threshold on this prediction. So this is all nice. So yes, and this is part of the exercise. 

Good. So now we are here with a summary over homogeneous coordinate systems and so on. And I think you should just read up on this. So this is, this is all, all superfine. And then you can go to and from homogeneous coordinates and so on. We will read up on that yourself. 

I think I've talked enough about homogeneous coordinates and that concept. So here you have a picture of Morton again. This is, I don't know that you know about this famous Lena picture. So now I'm going to tell an anecdote, but Morton has at some point decided that he would make that of himself. And he got Janus, his friend, to take this picture, which is, is like resembling the, the Lena picture, but with Morton in the, being the face. And then we went to a computer vision conference, the, the international, so it's CVPR, so computer vision and pattern recognition. 

It's, I think there are 12,000 participants this year. And then one, we were there and then one person stopped him and said, oh, isn't it you that's in that picture? So they recognized him. So he's becoming famous in the community for making this, for posting this picture. 

So that's good. So now we have, we want to derive an equation that tells us if you have points in 3D, where do they project to in the image plane? That's kind of the whole point of the thing. And that's why we've talked so much about homogeneous coordinates and all of that. So if we start by having a point that lies on the axis, set axis here. So you have the, the, the, the principle point, you have the image plane and you have this axis going, a second also the image plane in the set direction. Then the point where it, it, it, it, it, it cuts, it goes through the image in a certain point. 

And now this is of course drawn in one D, but remember that, oh, now I'm running out of blackboards. I think I should remove some things. I can go back here and take some of the early computer vision stuff that I haven't used. 

Good. So remember that an image is a 2D plane and we have the, the, the, the principle point. Now think about it, that it's lying behind this plane, but it's like kind of in the middle of the, the, the image, because we place this, this detector strategically well such that the light that comes in will hit the detector. And therefore the, the, the point of where the, the principle point, the point where all the light goes through is somewhere in the middle of the image. So, and this means that it, it is a place here and we still have the convention of X and Y here. So the distance here, we can call it delta X and this distance up here, we can call delta Y. And, and this is, this is going to be important later on when we are going to define the, the parameters. So, so we want to go from a 3D coordinate in the world and then go to understand where in the image plane, and this means in the pixel coordinate system, that's what we're going to work in, will this point end up? So what pixel will the point project? And that, that'll be important. Good. So 0.0 in the image, where's that? I'll go back. 

Anyone want to volunteer? This is one of the easy questions. I shouldn't say that. And then a lot of you sit there and think, oh, where is that? So, so we have X going down, Y going out, where would, who will vote for that, that 0.0 is here? 

There's quite a lot. Who want to vote for it's there? What about this one? 

No one. That's good. It's up here, of course. That's, that's the, that's the origo of the image. Very good. So, if we just use the projective transformation, it's at the principle point, and that's why I, I, I have, I've now introduced these, these delta values to, to be able to translate from the point in the middle of image to the, the, to compensate for this, this translation in the image plane. 

Good. So the projection from the real world is now simply just this. So we have the x coordinate in the image is equal to the focal length divided by the z coordinate multiplied by the x coordinate plus this delta. I am writing this is of course a sine thing because it depends a little bit on the convention but let's just assume that I give these the right signs such that if this is a positive value it actually moves things correctly. Good so this is the projection to the image and the same goes for the y and that's written here so that should be fine. So we can then again make a matrix that does this scaling and translation and we call that k. So at some point be modifying it a little bit but in principle this is the important thing that is we have the focal length here and then we have zero and then we have I'm just gonna check that I do it right. We have the of course the delta x and delta y so we have delta x with zero the focal length delta y and then we have zero zero one right something like this and now this matrix we can multiply by the point b and then and that is the point that we have in homogeneous coordinates that we've projected from the 3D world to 2D using this part here and then we end up with a nice linear algebra expression for the camera model. So if we have different coordinate systems or we have multiple cameras we cannot just assume that the coordinates of the of the camera is in zero we need to introduce a coordinate system for the world as well. So this means that we need to project into the camera coordinate system and there so there's a translation and rotation involved in that and then from there we can project into the into the camera coordinate system and this is that we parameterize this transfer there's this transformation with a rotation and a translation and then we project that point to the to this with the rotation and translation to the camera coordinate system and then from the camera coordinate system we can then project onto the do this this projection into the image plane and so let's just look at it so so the projecting a single point here is that we have the camera in the point in the real world that is then here rotated and translated it results in the camera projection matrix multiplied by these intrinsic camera parameters and and and this is what it ends up looking like so this is the full camera model so let me just remove a little bit more so this was just this thing of point to line distance and I'm gonna remove this tree so we just end up with a this was the camera matrix k equals here so we have a point small pH is equal to the camera matrix multiplied by the rotation and translation in the 3d coordinate multiplied by the point in the world so this is simply just this projective geometry and you can see that these things or these three you'll also see it with this P which is yet another P but written with a little bit different font but that is how large is that what's the size of you can see it on the slide so it's not so we have here this one is 3 by 3 this one is 3 by 4 and then these two multiplied together will become a 3 by by 4 matrix so P is in so I can write it here this one is 3 by 3 this one is 3 by 4 this one is 4 by 1 so the resulting P that's in a 3 by 4 and that's the matrix we need to go from a world coordinate to a coordinate in the camera and it consists of these camera parameters which is the focal point the the the translation so the translation from the principal point to the origo that's in the camera plane and then it's the projection to the camera cord the camera coordinate system through a rotation a translation using homogeneous coordinates right and the scaling factor comes in by the by the focal length here so that's what what scales it to make things fit so so when you at some point get to camera calibration so that is knowing what is the intrinsic of the of the camera so that is the focal length and it's these principal point coordinates or distances and then there will also be some lens distortions that we will get to that at some point so that's the intrinsic parameters and then it will typically be the rotation and translation but if we are just having one camera we can say that okay the origo of this world coordinate system is in the origo or is in the principal point of my camera so I don't care but you can also have several cameras and therefore it will be typically be modeled relative between cameras this world coordinate system and that's where it comes into play but but these are the parameters and that's what you're gonna play around with and so it says here the translation is not the position of the camera what happens if the last coordinate pH is not one oh what happens then so that's a so if we have something here if it's zero we don't want to we don't want to talk about it but if it's if it's something else so so we have this pH equals something x and then we say it's three down here or even it might be minus three then what happens then to the equation here what happens to pH so what's the what's the dimensionality of pH anyone yes it's three by one and the third coordinate of that what is that that's the scaling fact exactly so doing this the scaling factor will also just be minus three in this case and then you'll just divide it you'll be able to divide it out and then get one in the homogeneous part and then nothing is really happening but as modern rights here that we get a scaled version of P cam but it's along the same line so the projection it projects to the same point so there's not nothing nothing really happens by that except if this scaling factor is zero then we are we're not defined good so this was the projection matrix so that the this funny written P is what is called the projection matrix which has the camera matrix part so the intrinsic camera parts and the intrinsic camera parameters here the rotation and the translation and remember in 3d we are working with typically working with two rotation axis so the elevation and the asymus of the rotations that's typically how we represented and how we will these two parameters will then give us a rotation matrix good so now we come to exercise that was easy so you now have the joy of going here to learn press content press week one go to exercise there's a PDF and when you press that you get this up and then there's a bunch of exercises that's that's going to be matrix vector multiplications to work with homogeneous coordinates and so on and then there's a part on the exercise on but we need to install open TV the check that works and then you do protective geometry using the this pinhole camera model and and yeah I think it's more less self-explanatory what you should be aware of is the dimensionality of things when you do matrix multiplications so so I the easy thing is to use numpy so that you represent all these vectors as numpy arrays so I'll just go back to my my code here and then we can we can look a little bit at it together so so if if we have a vector V and then we just make it into a list 3.2 right and and we have a vector we call w equals 4.2 and and then if we want to multiply these together we will we'll have a problem I actually don't know what happens if we say np dot dot will that will that work that does that take lists yeah that works so so this you can do you can do the dot product between if you do it this way but you cannot it doesn't I don't think it'll work if I say something like this so use this at operator it'll it'll say that this doesn't work you cannot take two lists and then multiply them this way so this has to be numpy arrays so if we try that what happens now now it now it's able to multiply them so so we get the same value of a very good so what if what if this one was a 2 by 2 matrix instead so we have something like that 4 comma minus minus 5 just to try something fun what happens now it actually works still so that you can all also do and now it comes out as an array so it's simply just multiplying the two so so so therefore as you can see that I was actually in doubt if if if this would this would work out but sometimes if you get into the problem that it's not gonna it's not gonna do as you please so so we can for example not we will not be able to multiply them because this would be element wise multiplication and they don't they don't fit in size but if you need to change the dimensionality so if we look at at v dot shape what do we get we get a 2 by 2 and w shape it says 2 comma and then nothing and that's because it's a 1d array and if you want to change it to a 2d array you can that's this simple trick something like this if you write this what will be then be oh w then be that was the one that I wanted and I'm writing it wrong then then it suddenly is a 2 by 1 and you also swap these two or can you is this all no this is not gonna work then you'd have to to do it this way so because there's nothing of course in the second dimension but then you could always transpose it and and no it's not gonna now now it now it's not gonna work with the multiplication afterwards let's just take that one take that one out and then if we transpose this you can see now it becomes a now it's a 1 by 2 this is just a little bit of fiddling around but it can it can sometime become handy to be able to do multiplications with the right dimensions and so on but it seems like it works fine to multiply a 1d vector onto a 2d matrix that should be fine so I think that's let's see if there's more to say on the exercise so use Python interactively that's what you've seen I've done that's just a recommendation you can use VS code give it a notebook spider whatever you prefer and by having this blockwise computation it's easier to run a bit at a time and and debug what you're doing so often when I do when I implement something I will all often start with these blocks and then when I have something that I'm pretty sure works I'll copy it into functions check that they work and then I'll make a separate Python file that actually contains the things that I wanted that I can run from a command line and then do the processing there so it's just a way of working with code so so it here just says that you can do the same thing with individual vectors but you can also put everything into a matrix numpy you don't need to make a lot of loops and so on and and there's this thing of converting from homogeneous to not homogeneous coordinates and so on and then use the TA it says that numpy is your friend but the TA is there actually also quite friendly so so they will they'll be happy to help you and they'll be here in 10 minutes so you have to be able to explain homogeneous coordinates convert from to and from homogeneous coordinates and then make a translation rotation using homogeneous console so this matrix vector multiplication and then two projections using the pinhole camera model and it is very useful so that was actually the last thing that I wanted to say is that this was this tree that I now deleted but but the reason that the pinhole camera model is actually a good is because we have lenses so so if we have the tree from and we know that that that light is is is then hitting the surface here and spreading out then we have not just the straight line coming here ending on the image plane but we have some kind of we have a lens system that then can pick up a comb of the light that that that comes from a point here so think of this as something that comes from the exact same point on the tree picks it up and then through the lens system maps it on to the the place on the image that is exactly one point and then another cone coming from here will then be be hitting the lens slightly different and will end up on another point on the image but since that it's a it's a cone of light that is captured by the lens system we get more photons on to the detector meaning that we can actually create an image if it was just this pinhole there would be too few photons that hits the lens and we would need very long exposure times so the lens ensures that we get a lot of light onto the detector and then we can actually make pictures and then it's amazing that what we can do with a small phone camera with a small lens like there's enough but that's due to the fact that that that there's also a lot of software in these cameras so good so so questions anything you'd like to ask I hope that you will I think I went a little bit fast through the the camera projection and so on but but I think it'll be very clear after you've done the exercise if not we will finish it here and you will get the the the help from the TAs in seven minutes from now good we'll close it you 