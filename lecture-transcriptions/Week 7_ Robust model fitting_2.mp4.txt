Okay. So, 

Speaker 1: I'm here, you're here, it's Friday, you've been looking forward to this all week. And now it's time to talk about one of my favorite topics, which is robust model fitting. And how's the time for you guys? Sound good? All right. 

And you are being notified that we are recording and people are watching this on the internet. And I would like two people to volunteer and give me feedback. In the lecture, we have one, a second person. 

It's very informal. I just need one more volunteer. Thank you. 

And then we can continue. So, in some of the other weeks, we had a lot of learning objectives for lecture, but here we have a very short list. So, you should be able to explain how the Huff transform works and you should be able to understand and implement Rensack. 

So, the thing we're doing today, we're looking exclusively at lines in 2D, because it's kind of easy to visualize, easier to understand. And then in later weeks, you get to apply Rensack also to higher dimensional problems like the homography or fundamental matrix, but we'll get to that. And before we jump further into it, I also think I want to just share that I really like Rensack. Rensack is one of those algorithms that you can actually apply outside of a computer vision context just any time you're trying to fit a model to some data. So, it's very nice. 

Table of contents. And now, for the whole thing we're talking about, we're talking about fitting straight lines. Can we fit a straight line to these data points? Yeah. Okay. Yes, we could do that. But now, let's say that our data looks like this. Can we fit a straight line to this? 

We can. If we just do some kind of least squares fitting, we end up with this, which we as humans, when we look at this, we can tell, okay, there are probably some points that are outliers and I can clearly see that there's a line here and Huff, Transform and Rensack that I teach you about today are how can we actually fit the line that you can see in this data when you have some outliers that you don't want to take into account. So, it's all about robustifying the way that we try to fit models. Because in practice, we don't care super much about being able to fit 2D lines, but it's nice to visualize and therefore I like putting it on the slides. Just everything is 2D lines today, but it'll be more in the future. 

High dimensions. And first, the Huff, Transform. So, what I show here is an example of an input image on the left and on the right hand side, we see the corresponding Huff, Transform of this image. We don't get know what it is, but we see it. And the image consists of a lot of white pixels that are background and then the black pixels, I say this is an edge or something we want to fit the line to. And then this point here in Huff Space, where there's a peak, that corresponds to the line that we would like to fit. 

And then we'll talk a bit more about what they are. But first, how do we represent a line? So, I guess, when you went, before you went to university, you were being taught math by someone else. And there, I assume you've seen something that looks like y equals ax plus b, like the stereotypical 2D line representation. But we don't want to use this because we can't really represent a completely vertical line. 

That's the singularity. So, we don't do that. Then you may say, okay, we have, in this course, we've been taught that we can represent a 2D line with homogeneous coordinates. 

Why don't we do that? And then I say to you, aha, but this is over parameterized. We use free numbers to represent two degrees of freedom. 

And that's very disadvantageous for the Huff Transform. We want exactly the number of degrees of freedom. So now we introduce a third way of representing a 2D line, which is this R and the theta representation. So, we have the angle of the line. That's one number. And then we have the closest distance from the origin or coordinate system to the line. 

And those are the two numbers we represented with. So, if R is equal to zero, the line goes through the origin or coordinate system. And the angle determines how it's rotated. And when R increases, then the line moves further away. So now with these two numbers, we can parameterize any line also completely vertical ones. And we can even easily convert lines of this form, the angle and the R into lines of the homogeneous form with this little formula here. 

Okay. Now, with just these two numbers, we can represent the line. And if we can limit the angle to be between minus pi half and pi half, and the R to be between minus D and D. So D is the diagonal length of the image. So we could have chosen different here. We could have chosen to limit the angle to a smaller interval. But here we allow both negative and positive distances. 

If the angle could go from zero to two pi, we could only have positive Rs. But this is the way to be parameterized for the half space. But now because we have these two ranges where we know any line that can be in our image will have parameters within this range, then when we have a line in our image, we can convert it to this representation, the angle and the R, and we can plot it somewhere on a 2D grid. And now the idea of the Hofton form is that each edge point, something we think could be part of the line, is allowed to vote on which lines it's in favor of. So the whole idea is each point gets to cast votes on all lines that go through that point, which is there are infinitely many lines going through the point. You just constrain it to go through the point, and then you can rotate the line all around that point. And any line that goes through a point we're interested in. And this also means that because a point can vote for all the lines going through the point, a point in the image corresponds to a line in half space, the line that goes through all the lines that go through the point. 

That's a lot of confusing words, so we'll see a concrete example on a few slides. And then we do this over and over for all points. So in practice, this looks like this. We start out with an empty half space, there's just zeroes here, and we have the half space parameterized as an image with discrete discretizations of R, discretizations of the angle, and now we look at a single point here in our image and say, this is this point. And then for all lines that could go through this point, we add a point for the corresponding line in half space. So now we've drawn the infinitely many lines that go through the single red point that is drawn as the line in half space. And then we choose another point in the image and draw all the lines that could go through this point. And then we choose another point in the image and draw all the lines that could go through this point. Are there any questions so far? 

What do you need a moment to admire the drawing? Yes. The question was whether the plot on the right shows which values of theta and R correspond to lines that intersect with the points in red. And exactly. 

And the thing we note, sorry. The question is what does R correspond to? D is the length of the diagonal of the image and R is in the range from minus D to D. So in the middle here, R is zero. So in the drawing shown here, R is positive. But if you flip R to be negative, then the line just moves on the other side of the origin. And then we can draw all the points in half space and end up with this image on the right. Another question. 

Yes. So for every line I can draw that goes through this single red point. There are infinitely many of these lines, but each time I can choose one of them and then I draw the corresponding point in half space. And then I rotate it a little bit and then I find what are the parameters of this line and I draw that in half space. And then I rotate all the lines that can go through this single red point and this turns into my line in half space. Yeah, the origin is, I'm not exactly sure. 

I guess the origin would be up here. It's different to, it's not easy to reason on the fly that are these parameterizations or this R and angle should correspond to this line. That is not the most intuitive representation to convert in your head, but I hope conceptually it makes sense that we have a space of lines where we can represent any line. And therefore the infinitely many lines that go through a point becomes a line in this space. 

So then now that we have drawn all the lines, all the points have been allowed to become lines in the half space. Now we have, we see that we have a very clear peak here because there are all of the points that lie kind of on this line will have voted on lines that go through something very close to this peak. So if we find what are the exact coordinates of this peak in the half space, then we know what is the most dominant line in this image. The point in half space that has received the most votes. So a peak in the half space corresponds to a line in the image. And we can use non-maximum suppression again to find this. And if we go just a few slides back here, you can see the only points I have in here are the three red points that lie on the line. 

And they all intersect in this point that ends up becoming the peak because that's the only line that all three of them have voted for. So questions? You're always welcome to ask questions on the fly. But that's the half transform for lines. And then we can choose to generalize this, go into more complex things. Let's say we want to find circles. Now we need to find some way of parameterizing a circle that could be with the center and the radius. 

But now suddenly we have three parameters. So each point in the image will now cast a cone in the half space. And crucially we need to store the 3D half space for a circle. So when we're trying to fit a model with three parameters, we need a three dimensional half space. Because we need to be able to represent every model we can fit in the half space. So if we have more than three degrees of freedom, if we want to fit a homography where we have eight degrees of freedom, or even a fundamental matrix, then this very quickly grows infeasible to allocate with sufficient resolution the half space for this object. 

So therefore we don't really use the half transform beyond two to three dimensions. But we do something else instead. That's called ransack, which was back then when everything needed to have some kind of pirate acronym. 

I don't know. So the basic idea of ransack is what if instead of computing the entire half space, there's so many zeros here. There's a lot of things I don't care about. What if we could sample points in half space directly? That's not so hard to do. We can just sample random parameters of model, then we have a point in half space. But what if instead we could sample random points in half space with the likelihood of sampling the point being proportional to how high that point in half space is? So we're more likely to sample a peak because there are more lines intersecting here. 

It would be really nice if we could sample points in half space with the likelihood being proportional to the half space image itself. And that's kind of what ransack allows us to do. And ransack is also a really deceptively simple method. 

So the first step, I'm already generalizing the language a bit. The first step of ransack is to randomly sample the minimum number of points we need to fit our model. And that's a very complicated way of saying we're trying to fit a line. How many points do I need to sample in order to completely fix the minimum number of points I need to sample to fix a 2D line? I need to sample two points because then I can draw a line that goes exactly through these two points. So the minimum number of points we need to fit the model we're working with. Then I've sampled two points, then I fit a line that goes exactly through these two points. And here we have again a visualization of some data and I've sampled at random two points, the two red ones, and I've drawn the green line that goes exactly through them. And now I ask the question, does this line fit my data well? 

And I think probably not. But how can I quantify this? Can I measure how well this line fits? And the way ransack does this is by introducing the concept of an inlier. So it's by this heuristic we say points that are closer than a certain threshold to the line within this light green area, we say these points are inliers. So everything outside this is an outlier with respect to this line. And now we can use the number of inliers to as a proxy for how well does this line fit our data. How well does this model fit the data we have if we're not working with lines? So we can sample two new points and fit their line. There is a question. It's a hyper-frameter what you choose to threshold to be. 

I'll say some things about it, not specific to certain applications, but it kind of depends what noise you expect your data to have. So it's a parameter you need to set. If I sample two new points, I can fit this line. It has 32 endliers. 

I sample new points. It gets 26. This line has 67. This line has 62 endliers. Incredible. 

This is like the biggest number I've ever seen. So therefore I write this down. Oh, there was a really great line I got there. So every time I find a new line that has more endliers than I've seen previously, I save what the number of endliers were and what the line was. 

And then I keep going. And then the line with the most endliers that is going to be quite a good fit. So the outline of the RANSAC algorithm is, as follows, sample the minimum number of points required to fit your model, fit the model, and data points with an error less than the threshold. They are inliers with respect to the fit model. And if the number of inliers is higher than anything you've seen before, save the number of inliers, update it, and update your best model. And then you do this for iterations. And in the end, you refit the model to all inliers of the best model. And that's it. 

That RANSAC works really well. Any questions? Yes? So the last point, you refit the model only to the inliers of the best model, not all of the points. 

Yeah. And it's what you get to implement in the exercise for 2D lines. It's very nice. 

And when you do that, there are some things that are nice to keep in mind. So if we represent lines using homogeneous coordinates, then it's very easy to compute the distance from a point to a line by doing the dot product between the line and the homogeneous version of your point. And this gives the distance to the line if and only if you've scaled your line such that a squared plus b squared equals one. 

So when you have fitted a line and rescaled it in this way, then computing the distance between all points and your line, that's doing a matrix of extra product and taking the absolute value. So it's also fast. So we can sample in-hub space without directly computing the hub space, and it's super useful for fitting models when we have outliers. And then we just have, as I already got a question about, a hyperparameter for the threshold to determine inliers. And we also need to choose the number of iterations. And a very important implication of the Rand-Sagall algorithm, because it is very widely used, is that being able to fit a model to exactly the number, to the minimum number of points, is very relevant. Because if I, in all of these examples, if I don't have nice code to fit a line to two points, but I can only figure out how to fit a line to three points, so I sample three points instead of two points, then I increase my probability that one of the three points I sample will be an outlier. So I will need to run it for more iterations. So the fewer points I can fit my model to while still fitting it deterministically and completely, the better it is. And you will get more guidance on how to choose the threshold later on, but we can actually do some pretty nice guidance by doing a bit of probability math to figure out how many iterations we need to run this algorithm for. 

So if we start out by doing the favorite thing in science, which is just assuming something. So now I assume we know epsilon, which is the fraction of outliers, and exactly 10% of my data, that's outliers. Now, when I'm in the case where I need n data points to fit a model, the probability of these n random sample points being all inliers is the probability of inlier, that's 1 minus the probability of outlier, to the power of n. So in this case, to the power of 2, because I need two points to fit my model. 

So the opposite of this, the complement, the probability that my two random points I've sampled has one or more outliers is 1 minus 1 minus epsilon to the power of n, because it's the other event, the complement. And now, if I run the Ranz-Seigard algorithm, I'm now performing these random samplings many times over and over. So big n is the number of times that I've randomly sampled, small n number of random points. And the probability that in all of these big n trials I've done so far, that the probability that all of them have contained at least one or more outliers is now the whole thing lifted to the power of big n. And now, what is the complement of this? So the probability that at least one of these big n random samplings of lowercase n points that I've done will have had only inliers. That is just 1 minus 1 minus of 1 minus epsilon to the power of lowcase n to the power of uppercase n. So the probability that when I've sampled n points big n times, at least one of these will have been only inliers. And then I can solve for n and find a value for n. And then I can set p to something and say, now in other words, I want the probability to be like, I want to be 99% certain that in all of these n samplings I've done, at least one of them will be only inliers. 

Because as soon as I sample only inliers, I fit the model to the... and get all the inliers and get the biggest number I can get. So now I have a way of computing how many times we need to run ransack if I can decide how certain I want to be that I've actually found the best model. And this is very useful if we know epsilon. But it turns out it's a real world and we don't know epsilon. 

But we can estimate an upper bound of epsilon while we're running ransack. So if we introduce a new variable called s, and s is now the number of inliers we saw when we fitted the best model so far. So this is the biggest number of inliers we've seen. And m is the total number of data points in our dataset. Then we've seen s inliers out of these m points. So there must be at least s over m inliers. So 1 minus this is an upper bound for how many outliers there can be. Because we've already identified something that has so many inliers. 

So in the worst case, the rest is outliers. And now we can estimate by using the math from the previous slide and plugging in our estimate of epsilon. We can estimate an upper bound on the number of iterations we require. And the nice thing about this is each time we find a new model with more inliers we get a new s, we can lower epsilon hat, and this will also lower n hat. And then we can recompute n hat. Each time we find a new model with more inliers, and once we run this entire thing for more than n hat iterations we can be sure that with probability p we have found a model with only inliers and fitted it to our data. So we have found the best model. 

And then we don't have to choose n, then we just have the threshold left. A question has arrived. So p is this guy here. The question was what is p? So p is the probability that once I have done this sampling big n times I will have sampled at least one sample that contained only inliers which is the whole thing I'm interested in. 

So if I set p very high I will find an n here that's also very high but if I run for this n this amount of times I will be guaranteed that the probability is very high that I sample only inliers and at least one of them. Ha! And now we just left with a few practical mathematical remarks because now in today's exercise you will be working with 2D points and you sample two random points and then you ask yourself wait how is it again that I fit a line in homogeneous coordinates to these? 

But worry not we will talk about it together. What do we know about the line that we want to fit to our two points? Well if the line fits the points then it must have distance 0 to the points. 

So the dot product of the line with the first point should be 0 the dot product of the line with the second point should also be 0. And how can we find L? We only know p1 and p2. How can we find L such that the dot product of it with p1 is 0 and the dot product with p2 is 0? So if we for a moment forget that they are homogeneous coordinates and just say everything is vectors. It's 3D vectors. Now we are saying we want to find some unknown vector L that is orthogonal to p1 and it's orthogonal to p2. So it turns out that the thing we can actually do is to take the crush product of our two points in homogeneous, 2D points in homogeneous coordinates but if we think about them as 3D vectors, take the crush product get out a vector that's perpendicular to both of them and now think of this as a line in homogeneous coordinates. This is actually how you fit a line in homogeneous coordinates to 2D points. 

Exactly 2 2D points. And that's pretty neat. So that was it for the lecture. You now should be able to explain how the half transform works. I hope so. And you should be able to understand and implement RANSAC. 

But before you go to the exercise, I would like to do a midterm evaluation with you guys. Which I have in my browser here. Yes. 

So now there is a QR code here that I would like you to scan with your phones. And before I forget it, there are also some... It's unrelated to the midterm, but there are some nice people conducting assigned indoor climate measuring thing. So after the midterm evaluation, you have more energy for scanning QR codes. Please go over here and scan the QR code on the wall and help these people doing their thesis. 

But I think once you scan this, there's like two tabs and you can press on the other tab. Do I have to start things? Is it working for you? 

This is the first time I'm trying this tool live. Have you said things? Ah. No? Have you submitted things? Yes. Oh. Sorry. I'm confused. I'm just trying to... what? 

Oh wait, you can't do anything. It's... Hmm. Uh... Oh. That's... okay, now I have... I have some results now. This is going less fluently than I was hoping when I found this tool. 

But that's the punishment you get for trying things live. Okay, now you can submit things and you can also go through and vote on the other things that people have written. Okay. I'll give you, uh, let's say 30 seconds more to just go through the other messages, vote on the ones you agree with and submit one or two of your own if you haven't already. 

And then after those 30 seconds, we go to the next point, which is what could be improved. And it's very... it's just... as a teacher, it's very nice to hear from you guys what you actually think. And this is anonymous, so... I'm the highlight. Very good. I'm glad to hear. All right, I will see if I can close this one. Okay. These are not responses to the first question. I should be improved. 

I think the... my use of VBOX could be improved. Is it okay with you guys if I set up a quiz on Learn where you can answer this part of the question? Because I don't think I can figure out how to do this. 

Right now. But... thank you for the answers to the first question and for the second question if you managed to submit those. Now you can go to the exercise and scan the indoor climate quality QR code or come down to give feedback if you're a feedback person. Thank you so much. 